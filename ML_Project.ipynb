{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "0wstQCMUXdIv",
    "outputId": "8732ac35-b99b-4fb6-81e1-1bd1c90b2888"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1b0bc7fcad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#uploading the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#uploading the dataset\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yXBhWDdwaKFb"
   },
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "import pandas as pd\n",
    "import io\n",
    "raw_dataset = pd.read_csv(io.BytesIO(uploaded['dataset.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OkSaeVo43n4"
   },
   "outputs": [],
   "source": [
    "#drop unique observations feature URL\n",
    "#and drop the state \n",
    "feature for being useless and full of missing data\n",
    "raw_dataset = raw_dataset.drop(columns=['URL','WHOIS_STATEPRO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IokZMtQRccHx"
   },
   "outputs": [],
   "source": [
    "#split the features and the output/y\n",
    "#features are the subset than contains all rows and all columns excpet last column\n",
    "features = raw_dataset.iloc[:, :-1].values\n",
    "#y is the subset that contains all rows of the last column\n",
    "y = raw_dataset.iloc[:, raw_dataset.shape[1] - 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05TbTok7zghu"
   },
   "outputs": [],
   "source": [
    "#take care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = 'None',strategy = 'most_frequent')\n",
    "charsetImputer = imputer.fit(features[:, 2:3])\n",
    "features[:, 2:3] = charsetImputer.transform(features[:, 2:3])\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "serverImputer = imputer.fit(features[:, 3:4])\n",
    "features[:, 3:4] = serverImputer.transform(features[:, 3:4])\n",
    "imputer = SimpleImputer(missing_values = 'None',strategy = 'most_frequent')\n",
    "serverImputer = imputer.fit(features[:, 3:4])\n",
    "features[:, 3:4] = serverImputer.transform(features[:, 3:4])\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "contLengthImputer = imputer.fit(features[:, 4:5])\n",
    "features[:, 4:5] = contLengthImputer.transform(features[:, 4:5])\n",
    "\n",
    "imputer = SimpleImputer(missing_values = 'None',strategy = 'most_frequent')\n",
    "countryImputer = imputer.fit(features[:, 5:6])\n",
    "features[:, 5:6] = countryImputer.transform(features[:, 5:6])\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "restImputer = imputer.fit(features[:, 8:18])\n",
    "features[:, 8:18] = restImputer.transform(features[:, 8:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PjIUlIyBGFCq"
   },
   "outputs": [],
   "source": [
    "#Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "features[:, 2] = labelencoder.fit_transform(features[:, 2])\n",
    "features[:, 3] = labelencoder.fit_transform(features[:, 3])\n",
    "features[:, 5] = labelencoder.fit_transform(features[:, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sh-NFObVIylt"
   },
   "outputs": [],
   "source": [
    "#Convert regdate to a number with reference to the oldest date\n",
    "import datetime\n",
    "\n",
    "referenceDateStr = '01/01/1985 00:00'\n",
    "referenceDate = datetime.datetime.strptime(referenceDateStr, '%d/%m/%Y %H:%M')\n",
    "\n",
    "for i in range(features.shape[0]):\n",
    "  try:\n",
    "    thisDate = datetime.datetime.strptime(features[i, 6], '%d/%m/%Y %H:%M')\n",
    "  except ValueError:\n",
    "    features[i, 6] = 'None'\n",
    "    continue\n",
    "  diff = thisDate - referenceDate\n",
    "  features[i, 6] = diff.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fa0X_GfsXNpS"
   },
   "outputs": [],
   "source": [
    "#Convert upDate to a number with reference to the oldest date\n",
    "referenceDateStr = '01/01/1985 00:00'\n",
    "referenceDate = datetime.datetime.strptime(referenceDateStr, '%d/%m/%Y %H:%M')\n",
    "\n",
    "for i in range(features.shape[0]):\n",
    "  try:\n",
    "    thisDate = datetime.datetime.strptime(features[i, 7], '%d/%m/%Y %H:%M')\n",
    "  except ValueError:\n",
    "    features[i, 7] = 'None'\n",
    "    continue\n",
    "  diff = thisDate - referenceDate\n",
    "  features[i, 7] = diff.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcZNFrBEWiQL"
   },
   "outputs": [],
   "source": [
    "#now deal with the issue of wrong dates\n",
    "\n",
    "imputer = SimpleImputer(missing_values = 'None',strategy = 'most_frequent')\n",
    "regDateImputer = imputer.fit(features[:, 6:7])\n",
    "features[:, 6:7] = regDateImputer.transform(features[:, 6:7])\n",
    "\n",
    "imputer = SimpleImputer(missing_values = 'None',strategy = 'most_frequent')\n",
    "upDateImputer = imputer.fit(features[:, 7:8])\n",
    "features[:, 7:8] = upDateImputer.transform(features[:, 7:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZHrY3RGYahi"
   },
   "outputs": [],
   "source": [
    "#split features and y into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRqPFRwd_kfS"
   },
   "outputs": [],
   "source": [
    "#scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "egbHvSunD255",
    "outputId": "9ab805dc-1cdd-4837-e49e-eedc5214a125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 93.05%, Test Accuracy = 91.32%\n"
     ]
    }
   ],
   "source": [
    "#logistic regression classifier with all features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "lr_clf.predict(X_train)\n",
    "print('Training Accuracy = %.2f%%, Test Accuracy = %.2f%%'%(lr_clf.score(X_train, y_train)* 100, lr_clf.score(X_test, y_test)* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "PoYff2XXWUi7",
    "outputId": "696ccfdc-9fd3-4eb2-9ed5-ee646f0c74e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of dimensions when conserving 93% of variance = 9\n",
      "Training Accuracy = 88.69%, Test Accuracy = 57.98%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Number of dimensions when conserving 96% of variance = 10\n",
      "Training Accuracy = 88.69%, Test Accuracy = 58.26%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Number of dimensions when conserving 99% of variance = 12\n",
      "Training Accuracy = 91.71%, Test Accuracy = 85.15%\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#logistic regression classifier with PCA used for dimensionality reduction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "for cov in [0.9, 0.95, 0.99]:\n",
    "  print('\\n')\n",
    "  pca = PCA(n_components = cov)\n",
    "  X_trainPca = pca.fit_transform(X_train)\n",
    "  X_testPca = pca.fit_transform(X_test)\n",
    "  expCov = sum(pca.explained_variance_ratio_)\n",
    "  print(\"Number of dimensions when conserving %.0f%% of variance = %d\"%(expCov*100, X_trainPca.shape[1]))\n",
    "  lr_clfPca = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_trainPca, y_train)\n",
    "  lr_clfPca.predict(X_trainPca)\n",
    "  print('Training Accuracy = %.2f%%, Test Accuracy = %.2f%%'%(lr_clfPca.score(X_trainPca, y_train)* 100, lr_clfPca.score(X_testPca, y_test)* 100))\n",
    "  print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bCWnK_E8oHBJ",
    "outputId": "92738412-f035-4a3c-a95a-bde671325eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 92.91%, Test Accuracy = 91.32%\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with date columns dropped\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train_no_date = np.delete(X_train, np.s_[7:9], 1)\n",
    "X_test_no_date = np.delete(X_test, np.s_[7:9], 1)\n",
    "lr_clf_no_date = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train_no_date, y_train)\n",
    "lr_clf_no_date.predict(X_train_no_date)\n",
    "print('Training Accuracy = %.2f%%, Test Accuracy = %.2f%%'%(lr_clf_no_date.score(X_train_no_date, y_train)* 100, lr_clf_no_date.score(X_test_no_date, y_test)* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e8WHD91Eradz",
    "outputId": "3f1727a3-46ad-4903-b3fb-bc2206f43e37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 92.56%, Test Accuracy = 91.88%\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with date & country columns dropped\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_no_count = np.delete(X_train, np.s_[6:9], 1)\n",
    "X_test_no_count = np.delete(X_test, np.s_[6:9], 1)\n",
    "lr_clf_no_count = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train_no_count, y_train)\n",
    "lr_clf_no_count.predict(X_train_no_count)\n",
    "print('Training Accuracy = %.2f%%, Test Accuracy = %.2f%%'%(lr_clf_no_count.score(X_train_no_count, y_train)* 100, lr_clf_no_count.score(X_test_no_count, y_test)* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9U8rRM2mt7D9",
    "outputId": "8286739a-399c-46de-cd68-a2d92642c3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 90.31%, Test Accuracy = 89.36%\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with Charset & server columns dropped\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_no_count = np.delete(X_train, np.s_[2:4], 1)\n",
    "X_train_no_count = np.delete(X_train_no_count, np.s_[3:6], 1)\n",
    "X_test_no_count = np.delete(X_test, np.s_[2:4], 1)\n",
    "X_test_no_count = np.delete(X_test_no_count, np.s_[3:6], 1)\n",
    "lr_clf_no_count = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train_no_count, y_train)\n",
    "lr_clf_no_count.predict(X_train_no_count)\n",
    "print('Training Accuracy = %.2f%%, Test Accuracy = %.2f%%'%(lr_clf_no_count.score(X_train_no_count, y_train)* 100, lr_clf_no_count.score(X_test_no_count, y_test)* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GRIOGET5QF_g",
    "outputId": "2a88b0f5-71a8-40f8-93e2-852b44b77892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 39.40, Testing Accuracy: 82.63\n",
      "trainig cross validation accuracy = 0.466417 , cross valididation test accuracy = 0.457388\n"
     ]
    }
   ],
   "source": [
    "#Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "gnb_model = GaussianNB() \n",
    "gnb_model.fit(X_train, y_train) \n",
    "  \n",
    "# making predictions on the testing set \n",
    "y_pred = gnb_model.predict(X_test) \n",
    "y_train_pred = gnb_model.predict(X_train)\n",
    "train_accuracy = gnb_model.score(X_train,y_train)\n",
    "test_accuracy = gnb_model.score(X_test,y_test)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}, Testing Accuracy: {test_accuracy*100:.2f}\")  \n",
    "\n",
    "## Cross Validation\n",
    "results =  cross_validate(gnb_model, X_train, y_train, cv= 5,return_train_score=True,scoring='neg_mean_squared_error')\n",
    "test_score =  -np.mean(results['test_score'])\n",
    "training_score = -np.mean(results['train_score'])\n",
    "print(\"trainig cross validation accuracy = %f , cross valididation test accuracy = %f\"%(1-training_score,1-test_score))\n",
    "\n",
    "# comparing actual response values (y_test) with predicted response values (y_pred) \n",
    "#from sklearn import metrics \n",
    "#print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "#print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_train, y_train_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UigxeXU-VItg",
    "outputId": "cab8a786-a849-4394-d425-182549299e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy = 0.984551,  testing accuracy = 0.851541\n",
      "trainig cross validation accuracy = 0.990696 , cross valididation test accuracy = 0.955755\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier using Information Gain criterion, maximum depth of 9, 5 classifiers, and random_state=3\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier= RandomForestClassifier(max_depth=9, n_estimators=5, criterion= 'gini')\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "train_results = classifier.score(X_train,y_train)\n",
    "test_results =classifier.score(X_test ,y_test)\n",
    "\n",
    "print('training accuracy = %f,  testing accuracy = %f'%(train_results, test_results))\n",
    "# using cross validation to decrease over fitting\n",
    "results =  cross_validate(classifier, X_train, y_train, cv= 5,return_train_score=True,scoring='neg_mean_squared_error')\n",
    "test_score =  -np.mean(results['test_score'])\n",
    "training_score = -np.mean(results['train_score'])\n",
    "print(\"trainig cross validation accuracy = %f , cross valididation test accuracy = %f\"%(1-training_score,1-test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hk9TwCr8VlIr",
    "outputId": "4f371d03-c486-46e3-8399-84e7be322ce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy = 0.990871,  testing accuracy = 0.879552\n",
      "trainig cross validation accuracy = 0.994733 , cross valididation test accuracy = 0.962780\n"
     ]
    }
   ],
   "source": [
    "#  Adaboost Ensemble Model using decision trees classifier with Information Gain criterion, maximum depth of 3, 10 classifiers, and random_state=3\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "d_tree= DecisionTreeClassifier(max_depth=2)\n",
    "classifier= AdaBoostClassifier(base_estimator=d_tree, n_estimators=17)\n",
    "\n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "train_results = classifier.score(X_train,y_train)\n",
    "test_results =classifier.score(X_test,y_test)\n",
    "\n",
    "print('training accuracy = %f,  testing accuracy = %f'%(train_results, test_results))\n",
    "\n",
    "#using Cross validation to decrease overfitting\n",
    "results =  cross_validate(classifier, X_train, y_train, cv= 5,return_train_score=True,scoring='neg_mean_squared_error')\n",
    "test_score =  -np.mean(results['test_score'])\n",
    "training_score = -np.mean(results['train_score'])\n",
    "print(\"trainig cross validation accuracy = %f , cross valididation test accuracy = %f\"%(1-training_score,1-test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NW51MgDPDFiL",
    "outputId": "c7efd4c1-63ee-4085-816b-b6d14a4e26d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy = 0.936798,  testing accuracy = 0.910364\n",
      "trainig cross validation accuracy = 0.937675 , cross valididation test accuracy = 0.935389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "classifier = SVC(kernel='linear') \n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "train_results = classifier.score(X_train,y_train)\n",
    "test_results =classifier.score(X_test,y_test)\n",
    "print('training accuracy = %f,  testing accuracy = %f'%(train_results, test_results))\n",
    "results =  cross_validate(classifier, X_train, y_train, cv= 5,return_train_score=True,scoring='neg_mean_squared_error')\n",
    "test_score =  -np.mean(results['test_score'])\n",
    "training_score = -np.mean(results['train_score'])\n",
    "print(\"trainig cross validation accuracy = %f , cross valididation test accuracy = %f\"%(1-training_score,1-test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4hEMl2LiYrUc",
    "outputId": "45bd6f9f-d7f4-4cdc-cd88-5740fd25b085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy = 0.945927,  testing accuracy = 0.927171\n",
      "trainig cross validation accuracy = 0.944522 , cross valididation test accuracy = 0.940309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "classifier = SVC(gamma='scale') \n",
    "classifier = classifier.fit(X_train,y_train)\n",
    "train_results = classifier.score(X_train,y_train)\n",
    "test_results =classifier.score(X_test,y_test)\n",
    "print('training accuracy = %f,  testing accuracy = %f'%(train_results, test_results))\n",
    "results =  cross_validate(classifier, X_train, y_train, cv= 5,return_train_score=True,scoring='neg_mean_squared_error')\n",
    "test_score =  -np.mean(results['test_score'])\n",
    "training_score = -np.mean(results['train_score'])\n",
    "print(\"trainig cross validation accuracy = %f , cross valididation test accuracy = %f\"%(1-training_score,1-test_score))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML Project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
